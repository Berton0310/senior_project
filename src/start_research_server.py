#!/usr/bin/env python3
"""
ç ”ç©¶æœå‹™å™¨å•Ÿå‹•è…³æœ¬ï¼ˆç¨ç«‹ç‰ˆï¼‰
- å°‡åŸæœ¬ src/app/api/main.py çš„ç¨‹å¼æ•´åˆé€²æœ¬æª”
- ä¸å†ä»¥æ¨¡çµ„åŒ¯å…¥æ–¹å¼è¼‰å…¥ app
"""

# åŸºæœ¬èˆ‡è·¯å¾‘è¨­å®š
import json
import asyncio
import time
from datetime import datetime
from pprint import pformat
import uvicorn
from bson.objectid import ObjectId  # ä¿ç•™åŸçµæ§‹ï¼Œç”¨æ–¼æœªä¾†æ“´å……ï¼ˆç›®å‰æœªå•Ÿç”¨ï¼‰
from pymongo import MongoClient  # ä¿ç•™åŸçµæ§‹ï¼Œç”¨æ–¼æœªä¾†æ“´å……ï¼ˆç›®å‰æœªå•Ÿç”¨ï¼‰
from pydantic import BaseModel
from fastapi.responses import FileResponse, StreamingResponse
from fastapi import UploadFile, File, HTTPException
from starlette.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi import FastAPI, Query, Request, HTTPException
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
import sys
import os
import logging
import re
import json
import shutil
from pathlib import Path
import traceback
# ç¢ºä¿å¯åŒ¯å…¥ src.*ï¼ˆä¾›ç ”ç©¶ä»£ç†èˆ‡è¨­å®šä½¿ç”¨ï¼‰
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

# ç¬¬ä¸‰æ–¹å¥—ä»¶

# ===== æ‡‰ç”¨èˆ‡ CORS è¨­å®š =====
app = FastAPI()

# è¨­å®šç·¨ç¢¼
if sys.platform == "win32":
    # Windows ç³»çµ±è¨­å®š
    import locale
    try:
        locale.setlocale(locale.LC_ALL, 'zh_TW.UTF-8')
    except:
        try:
            locale.setlocale(locale.LC_ALL, 'Chinese_Taiwan.950')
        except:
            pass

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # é–‹ç™¼ç’°å¢ƒå…è¨±æ‰€æœ‰ä¾†æºï¼Œç”Ÿç”¢ç’°å¢ƒè«‹é™åˆ¶
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨åŸŸé©—è­‰éŒ¯èª¤è™•ç†å™¨


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    logger.error(f"è«‹æ±‚é©—è­‰å¤±æ•—: {exc.errors()}")
    logger.error(f"è«‹æ±‚é«”: {await request.body()}")
    return JSONResponse(
        status_code=422,
        content={
            "detail": "è«‹æ±‚è³‡æ–™æ ¼å¼éŒ¯èª¤",
            "errors": exc.errors(),
            "body": (await request.body()).decode('utf-8') if request.method == "POST" else None
        }
    )

# ===== ä¸Šå‚³èˆ‡éœæ…‹æª”æ¡ˆè¨­å®š =====
# ç›´æ¥æŒ‡å®šæ—¢æœ‰çš„ tmp ç›®éŒ„ï¼ˆä¸è‡ªå‹•å»ºç«‹ï¼‰
TMP_DIR = r"C:\Users\berto\Desktop\capstone project\tmp"
TMP_IMAGE_DIR = r"C:\Users\berto\Desktop\capstone project\tmp\images_table"
TMP_OUTPUT_DIR = r"C:\Users\berto\Desktop\capstone project\tmp\tmp_doc"
MAX_UPLOAD_BYTES = 25 * 1024 * 1024  # 25MB ä¸Šé™
DOC_ID_DIR = r'C:\Users\berto\Desktop\capstone project\tmp\document_file'
# å°‡ tmp ç›®éŒ„æ›è¼‰ç‚ºå¯ç›´æ¥å­˜å–çš„éœæ…‹è·¯ç”±
try:
    app.mount("/uploads", StaticFiles(directory=TMP_DIR), name="uploads")
except Exception:
    # è‹¥ç›®éŒ„ä¸å­˜åœ¨æˆ–å…¶å®ƒåŸå› å°è‡´æ›è¼‰å¤±æ•—ï¼Œä¸é˜»æ–·æœå‹™å•Ÿå‹•
    logger.exception("æ›è¼‰ /uploads éœæ…‹è·¯ç”±å¤±æ•—ï¼Œè«‹ç¢ºèªç›®éŒ„æ˜¯å¦å­˜åœ¨ï¼š%s", TMP_DIR)

# ===== MongoDB é€£ç·šè¨­å®š =====
client = MongoClient(
    "mongodb+srv://root:root123@cluster0.pbz1j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0",
    serverSelectionTimeoutMS=5000,  # 5ç§’å…§é¸æ“‡ä¼ºæœå™¨
    connectTimeoutMS=10000,         # 10ç§’é€£ç·šè¶…æ™‚
    socketTimeoutMS=20000,          # 20ç§’ socket è¶…æ™‚
    maxPoolSize=10,                 # æœ€å¤§é€£ç·šæ± å¤§å°
    minPoolSize=1,                  # æœ€å°é€£ç·šæ± å¤§å°
    maxIdleTimeMS=30000,           # 30ç§’é–’ç½®è¶…æ™‚
    retryWrites=True,              # é‡è©¦å¯«å…¥
    retryReads=True                # é‡è©¦è®€å–
)
db = client.test  # database
collection = db.umodoc_main

# æ¸¬è©¦ MongoDB é€£ç·š
try:
    # æ¸¬è©¦é€£ç·š
    client.admin.command('ping')
    logger.info("âœ… MongoDB é€£ç·šæˆåŠŸ")
except Exception as e:
    logger.error(f"âŒ MongoDB é€£ç·šå¤±æ•—: {e}")
    # ä¸ä¸­æ–·æœå‹™ï¼Œä½†è¨˜éŒ„éŒ¯èª¤

# ===== SSE å·¥å…· =====


def sse_event(payload: dict) -> str:
    try:
        data = json.dumps(payload, ensure_ascii=False)
    except Exception:
        data = json.dumps(
            {"type": "error", "message": "serialization failed"}, ensure_ascii=False)
    return f"data: {data}\n\n"

# ===== æª”æ¡ˆå¯«å…¥å·¥å…· =====


def _write_result_to_file(result: dict, started_at: str, ended_at: str, elapsed_seconds: float, filename: str = "output.txt"):
    """å°‡ç ”ç©¶çµæœå¯«å…¥æª”æ¡ˆï¼ˆèˆ‡ run_research.py ä¸€è‡´é¢¨æ ¼ï¼‰ã€‚"""
    try:
        # å»é‡ timingsï¼šä¿ç•™æ¯å€‹æ¨™ç±¤çš„æœ€å¾Œä¸€æ¬¡è¨˜éŒ„
        if isinstance(result, dict) and "timings" in result:
            timings = result["timings"]
            if isinstance(timings, list):
                # å»ºç«‹æ¨™ç±¤åˆ°æœ€å¾Œæ™‚é–“çš„æ˜ å°„
                last_timings = {}
                for timing in timings:
                    if isinstance(timing, str) and ": " in timing:
                        label, time_str = timing.split(": ", 1)
                        last_timings[label] = time_str

                # é‡å»ºå»é‡å¾Œçš„ timings
                result = result.copy()
                result["timings"] = [
                    f"{label}: {time_str}" for label, time_str in last_timings.items()]

        with open(filename, "w", encoding="utf-8") as f:
            f.write(
                f"started_at: {started_at}\nended_at: {ended_at}\nelapsed_seconds: {elapsed_seconds:.2f}\n")
            f.write("\n===== result (pretty) =====\n")
            f.write(pformat(result, depth=5, width=120))
            if isinstance(result, dict) and "final_report" in result:
                f.write("\n\n===== final_report =====\n")
                f.write(str(result["final_report"]))
    except Exception as write_err:
        logger.warning(f"å¯«å…¥ {filename} å¤±æ•—: {write_err}")

# ===== ç°¡æ˜“æ–‡ä»¶æš«å­˜ï¼ˆä¾›å‰ç«¯ load-document ä½¿ç”¨ï¼‰ =====


DOCUMENT_STORE = {
    "title": "ç ”ç©¶æ–‡ä»¶",
    "content": "<p>å°šæœªæœ‰å…§å®¹</p>",
    "characterLimit": 100000,
}


def _update_document_content(html: str):
    """å°‡ final_report å¯«å…¥æš«å­˜å€ï¼Œä¾› /load-document å›å‚³ã€‚"""
    try:
        if html and isinstance(html, str):
            # è‹¥å…§å®¹åŒ…å« Markdown æ¨™é¡Œï¼Œå¾ç¬¬ä¸€å€‹ '#' é–‹å§‹æˆªå–
            try:
                first_hash_idx = html.find("#")
                normalized = html[first_hash_idx:] if first_hash_idx != -1 else html
            except Exception:
                normalized = html
            DOCUMENT_STORE["content"] = normalized
    except Exception as e:
        logger.warning(f"æ›´æ–°æ–‡ä»¶æš«å­˜å¤±æ•—: {e}")

# ===== è³‡æ–™æ¨¡å‹ï¼ˆä¿ç•™åŸçµæ§‹ï¼‰ =====


class DocumentContent(BaseModel):
    html: str
    json_data: dict  # é¿å…èˆ‡ BaseModel.json() è¡çª
    text: str


class PageSize(BaseModel):
    label: str
    width: float
    height: float
    default: bool


class Page(BaseModel):
    size: PageSize
    # å¯æ“´å……å…¶ä»–æ¬„ä½ï¼ˆzoomLevel, margin ç­‰ï¼‰


class DocumentData(BaseModel):
    content: DocumentContent
    page: Page
    document: dict


# ===== AI åŠ©æ‰‹ï¼ˆä¿ç•™åŸçµæ§‹ï¼‰ =====
class AssistantPayload(BaseModel):
    lang: str
    input: str
    command: str
    output: str


class AssistantContent(BaseModel):
    html: str
    text: str
    json_data: dict


class AssistantRequest(BaseModel):
    payload: AssistantPayload
    content: AssistantContent


class AssistantResponse(BaseModel):
    success: bool
    message: str
    content: str = ""
    error: str = ""


# ===== æ–‡æª”å„²å­˜è³‡æ–™æ¨¡å‹ =====
class DocumentContent(BaseModel):
    html: str
    json: dict
    text: str


class PageSize(BaseModel):
    label: str
    width: float
    height: float
    default: bool


class Page(BaseModel):
    size: PageSize
    # åŠ ä¸Šå…¶ä»–æ¬„ä½ä¹Ÿå¯ä»¥ï¼Œå¦‚ zoomLevel, margin ç­‰ï¼ˆä¾éœ€æ±‚ï¼‰


class DocumentData(BaseModel):
    content: DocumentContent
    page: Page
    document: dict


class DocumentSaveRequest(BaseModel):
    documentId: str
    reportTitle: str = ""  # è¨­ç‚ºå¯é¸ï¼Œæä¾›é è¨­å€¼
    data: DocumentData  # ä½¿ç”¨æ–°çš„çµæ§‹åŒ–è³‡æ–™æ ¼å¼


class DocumentSaveResponse(BaseModel):
    success: bool
    message: str
    document_id: str = ""
    error: str = ""


class AssistantHandler:
    def __init__(self):
        self.commands = {
            "çºŒå¯«": self._continue_writing,
            "é‡å¯«": self._rewrite,
            "ç¸®å¯«": self._abbreviate,
            "æ“´å¯«": self._expand,
            "æ½¤è‰²": self._polish,
            "æ ¡é–±": self._proofread,
            "ç¿»è­¯": self._translate,
            "Continuation": self._continue_writing,
            "Rewrite": self._rewrite,
            "Abbreviation": self._abbreviate,
            "Expansion": self._expand,
            "Polish": self._polish,
            "Proofread": self._proofread,
            "Translate": self._translate,
        }

    def process_command(self, payload: AssistantPayload, content: AssistantContent) -> str:
        command = payload.command.strip()
        selected_text = payload.input.strip()

        print("æ”¶åˆ°AIåŠ©æ‰‹è«‹æ±‚:")
        print(f"  æŒ‡ä»¤: {command}")
        print(f"  é¸ä¸­æ–‡å­—: {selected_text}")
        print(f"  èªè¨€: {payload.lang}")
        print(f"  æ–‡ä»¶å…§å®¹é•·åº¦: {len(content.text)} å­—å…ƒ")

        if command in self.commands:
            return self.commands[command](selected_text, content)
        else:
            return self._custom_command(command, selected_text, content)

    def _continue_writing(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦çºŒå¯«çš„æ–‡å­—å…§å®¹ã€‚</p>"
        continuation = (
            f"<p>{selected_text}... é€™æ˜¯çºŒå¯«çš„å…§å®¹ã€‚æ ¹æ“šæ‚¨æä¾›çš„æ–‡å­—ï¼Œæˆ‘å°‡ç¹¼çºŒç™¼å±•é€™å€‹ä¸»é¡Œï¼Œ"
            f"æä¾›æ›´å¤šç›¸é—œçš„è³‡è¨Šå’Œè¦‹è§£ã€‚</p>"
        )
        return continuation

    def _rewrite(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦é‡å¯«çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return (
            f"<p>é‡å¯«ç‰ˆæœ¬ï¼š{selected_text}</p><p>é€™æ˜¯ä¸€å€‹é‡æ–°è¡¨é”çš„ç‰ˆæœ¬ï¼Œä¿æŒäº†åŸæ„ä½†ä½¿ç”¨äº†ä¸åŒçš„è¡¨é”æ–¹å¼ã€‚</p>"
        )

    def _abbreviate(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦ç¸®å¯«çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return f"<p>ç¸®å¯«ç‰ˆæœ¬ï¼š{selected_text[:50]}...</p>"

    def _expand(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦æ“´å¯«çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return (
            f"<p>æ“´å¯«ç‰ˆæœ¬ï¼š{selected_text}</p><p>é€™æ˜¯ä¸€å€‹æ›´è©³ç´°çš„ç‰ˆæœ¬ï¼ŒåŒ…å«äº†æ›´å¤šèƒŒæ™¯è³‡è¨Šã€ä¾‹å­å’Œè§£é‡‹ï¼Œè®“å…§å®¹æ›´åŠ è±å¯Œå’Œå®Œæ•´ã€‚</p>"
        )

    def _polish(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦æ½¤è‰²çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return (
            f"<p>æ½¤è‰²ç‰ˆæœ¬ï¼š{selected_text}</p><p>é€™å€‹ç‰ˆæœ¬ç¶“éäº†èªè¨€å„ªåŒ–ï¼Œè¡¨é”æ›´åŠ æµæš¢è‡ªç„¶ï¼Œç”¨è©æ›´åŠ ç²¾æº–ã€‚</p>"
        )

    def _proofread(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦æ ¡é–±çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return (
            f"<p>æ ¡é–±çµæœï¼š</p><p>åŸæ–‡ï¼š{selected_text}</p><p>ä¿®æ­£å»ºè­°ï¼šå·²æª¢æŸ¥æ‹¼å­—ã€èªæ³•å’Œè¡¨é”ï¼Œå…§å®¹åŸºæœ¬æ­£ç¢ºã€‚</p>"
        )

    def _translate(self, selected_text: str, content: AssistantContent) -> str:
        if not selected_text:
            return "<p>è«‹å…ˆé¸æ“‡è¦ç¿»è­¯çš„æ–‡å­—å…§å®¹ã€‚</p>"
        return (
            f"<p>ç¿»è­¯çµæœï¼š</p><p>åŸæ–‡ï¼š{selected_text}</p><p>è­¯æ–‡ï¼šThis is a translated version of the selected text.</p>"
        )

    def _custom_command(self, command: str, selected_text: str, content: AssistantContent) -> str:
        return f"<p>æ”¶åˆ°è‡ªå®šç¾©æŒ‡ä»¤ï¼š{command}</p><p>é¸ä¸­æ–‡å­—ï¼š{selected_text}</p><p>é€™æ˜¯ä¸€å€‹è‡ªå®šç¾©çš„AIè™•ç†çµæœã€‚</p>"


assistant_handler = AssistantHandler()


# ===== AI åŠ©æ‰‹ API =====
@app.post("/ai-assistant")
async def ai_assistant(request: AssistantRequest):
    try:
        result_content = assistant_handler.process_command(
            request.payload,
            request.content,
        )
        return AssistantResponse(
            success=True,
            message="AIåŠ©æ‰‹è™•ç†æˆåŠŸ",
            content=result_content,
        )
    except Exception as e:
        # åƒ…åœ¨ä¼ºæœå™¨ç«¯è¨˜éŒ„å®Œæ•´éŒ¯èª¤ï¼Œé¿å…å‘ä½¿ç”¨è€…æ´©æ¼å…§éƒ¨ç´°ç¯€
        logger.exception("AI åŠ©æ‰‹è™•ç†å¤±æ•—")
        return AssistantResponse(
            success=False,
            message="AIåŠ©æ‰‹è™•ç†å¤±æ•—",
            error="ç³»çµ±ç¹å¿™ï¼Œè«‹ç¨å¾Œå†è©¦",
        )


# ===== ç ”ç©¶é é¢èˆ‡ç ”ç©¶ APIï¼ˆéä¸²æµï¼‰ =====
@app.get("/research")
async def research_page():
    """æä¾›ç ”ç©¶é é¢"""
    html_path = Path(__file__).parent / "src" / "app" / "api" / "research.html"
    return FileResponse(html_path)


@app.post("/research/run")
async def run_research(request: dict):
    """åŸ·è¡Œç ”ç©¶ä¸¦è¿”å›çµæœï¼ˆéä¸²æµï¼‰"""
    try:
        question = request.get("question", "")
        if not question:
            return {"error": "è«‹æä¾›ç ”ç©¶å•é¡Œ"}

        # å‹•æ…‹åŒ¯å…¥ç ”ç©¶ä»£ç†ï¼ˆä»éœ€ src.* å¯åŒ¯å…¥ï¼‰
        from src.app.agents.research_agent import deep_researcher
        from src.app.config import Configuration

        config = Configuration()
        configurable = {**config.model_dump(mode="json")}
        configurable["allow_clarification"] = False
        run_config = {"configurable": configurable}

        # ç”Ÿæˆ task_idï¼ˆèˆ‡ä¸²æµç«¯é»ä¸€è‡´ï¼‰
        task_id = f"research_{int(time.time() * 1000)}_{question[:20]}"

        start_dt = datetime.now().isoformat(timespec="seconds")
        start_time = time.perf_counter()
        result = await deep_researcher.ainvoke(
            {"messages": [{"role": "user", "content": question}]},
            run_config,
        )
        end_time = time.perf_counter()
        end_dt = datetime.now().isoformat(timespec="seconds")
        elapsed = end_time - start_time

        # å¯«å…¥æª”æ¡ˆ
        _write_result_to_file(result, start_dt, end_dt, elapsed)
        # æ›´æ–°æš«å­˜æ–‡ä»¶å…§å®¹ä¾› /load-document ä½¿ç”¨
        _update_document_content(result.get("final_report", ""))

        return {
            "success": True,
            "final_report": result.get("final_report", "ç ”ç©¶å®Œæˆä½†æœªç”Ÿæˆå ±å‘Š"),
            "timings": result.get("timings", []),
            "document_id": task_id,  # æ–°å¢æ–‡æª” ID
        }

    except Exception:
        # åƒ…åœ¨ä¼ºæœå™¨ç«¯è¨˜éŒ„å®Œæ•´éŒ¯èª¤å †ç–Š
        logger.exception("ç ”ç©¶åŸ·è¡Œå¤±æ•—")
        return {"error": "ç ”ç©¶åŸ·è¡Œå¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦"}


# ===== å…¨åŸŸä»»å‹™ç®¡ç† =====
active_tasks: dict[str, asyncio.Task] = {}
# SSE é€£æ¥ç®¡ç†ï¼ˆç”¨æ–¼æª”æ¡ˆè™•ç†é€²åº¦æ¨é€ï¼‰
sse_connections: set[asyncio.Queue] = set()


def cancel_task(task_id: str):
    """å–æ¶ˆæŒ‡å®šçš„ä»»å‹™"""
    if task_id in active_tasks:
        task = active_tasks[task_id]
        if not task.done():
            task.cancel()
        del active_tasks[task_id]


def register_task(task_id: str, task: asyncio.Task):
    """è¨»å†Šä»»å‹™åˆ°å…¨åŸŸç®¡ç†"""
    active_tasks[task_id] = task


def broadcast_sse_event(event: dict):
    """å»£æ’­ SSE äº‹ä»¶åˆ°æ‰€æœ‰é€£æ¥"""
    for queue in list(sse_connections):
        try:
            # å°‡å­—å…¸è½‰ç‚º JSON å­—ä¸²ï¼Œèˆ‡ print_progress æ ¼å¼ä¸€è‡´
            import json
            event_str = json.dumps(event, ensure_ascii=False)
            queue.put_nowait(event_str)
        except Exception:
            # ç§»é™¤ç„¡æ•ˆé€£æ¥
            sse_connections.discard(queue)

# ===== ç ”ç©¶é€²åº¦ SSE ä¸²æµï¼ˆå³æ™‚ print_progressï¼‰ =====


@app.get("/research/stream")
async def research_stream(
    request: Request,
    question: str = Query(..., description="ç ”ç©¶å•é¡Œ"),
):
    async def event_generator():

        # ä»¥ asyncio.Queue æ”¶é›† print_progress çš„å³æ™‚è¨Šæ¯
        progress_queue: asyncio.Queue[str] = asyncio.Queue()

        # è¨»å†Šæ­¤é€£æ¥åˆ°å…¨åŸŸ SSE ç®¡ç†
        sse_connections.add(progress_queue)

        # ç¶å®šå›èª¿ï¼ˆä¸æš´éœ²å…§éƒ¨è³‡è¨Šï¼‰
        try:
            from src.app.agents import research_agent as ra
        except Exception:
            logger.exception("è¼‰å…¥ç ”ç©¶ä»£ç†å¤±æ•—")
            yield sse_event({"type": "error", "message": "ç³»çµ±åˆå§‹åŒ–å¤±æ•—"})
            return

        def progress_callback(msg: str):
            try:
                progress_queue.put_nowait(msg)
            except Exception:
                pass

        # è¨­å®šå›èª¿
        ra.print_progress.progress_callback = progress_callback

        # å•Ÿå‹•ç ”ç©¶èƒŒæ™¯ä»»å‹™
        async def run_research_task():
            try:
                from src.app.config import Configuration
                config = Configuration()
                configurable = {**config.model_dump(mode="json")}
                configurable["allow_clarification"] = False
                run_config = {"configurable": configurable}
                result = await ra.deep_researcher.ainvoke(
                    {"messages": [{"role": "user", "content": question}]},
                    run_config,
                )
                return result
            except Exception:
                logger.exception("ç ”ç©¶éç¨‹éŒ¯èª¤")
                return {"error": True}

        # è¨˜éŒ„é–‹å§‹æ™‚é–“ï¼Œå®Œæˆå¾Œèˆ‡çµæœä¸€åŒå¯«å…¥ output.txt
        started_at = datetime.now().isoformat(timespec="seconds")
        wall_start = time.perf_counter()
        task = asyncio.create_task(run_research_task())

        # ç”Ÿæˆä»»å‹™IDä¸¦è¨»å†Šåˆ°å…¨åŸŸç®¡ç†
        task_id = f"research_{int(time.time() * 1000)}_{question[:20]}"
        register_task(task_id, task)

        # é¦–æ¬¡äº‹ä»¶ï¼šå¸¶ task_id çš„éšæ®µèµ·å§‹äº‹ä»¶
        try:
            yield sse_event({
                "type": "stage_start",
                "stage": "deep_researcher",
                "message": "é–‹å§‹ç ”ç©¶",
                "task_id": task_id,
            })
        except Exception:
            pass

        try:
            # è¿´åœˆæ¨é€é€²åº¦ï¼Œç›´åˆ°ä»»å‹™å®Œæˆæˆ–å®¢æˆ¶ç«¯ä¸­æ–·
            while not task.done():
                # æª¢æŸ¥å‰ç«¯æ˜¯å¦å·²ä¸­æ–·é€£ç·šï¼ˆä½¿ç”¨è€…å–æ¶ˆï¼‰
                if await request.is_disconnected():
                    if not task.done():
                        task.cancel()
                    break
                try:
                    msg = await asyncio.wait_for(progress_queue.get(), timeout=0.25)

                    # è§£æä¸¦è½‰ç™¼æ¨™æº–åŒ–éšæ®µäº‹ä»¶
                    if "STAGE::" in msg:
                        try:
                            stage_segment = msg[msg.index("STAGE::"):]
                            # e.g., STAGE::research_supervisor::enter::iteration=3
                            parts = stage_segment.split("::")
                            stage_key = parts[1] if len(parts) > 1 else ""
                            iteration = None
                            if len(parts) >= 4 and parts[3].startswith("iteration="):
                                try:
                                    iteration = int(parts[3].split("=", 1)[1])
                                except Exception:
                                    iteration = None

                            stage_map = {
                                "clarify_with_user": "clarify",
                                "write_research_brief": "plan",
                                "research_supervisor": "execute",
                                "final_report_generation": "report",
                            }
                            stage_name = stage_map.get(stage_key)
                            if stage_name:
                                yield sse_event({
                                    "type": "stage",
                                    "stage": stage_name,
                                    "iteration": iteration,
                                })
                                continue
                        except Exception:
                            # è‹¥è§£æå¤±æ•—å‰‡é€€å›ä¸€èˆ¬é€²åº¦è¨Šæ¯
                            pass

                    # ä¸€èˆ¬é€²åº¦è¨Šæ¯
                    yield sse_event({"type": "progress", "message": msg})
                except asyncio.TimeoutError:
                    # ç©ºè½‰ï¼Œæª¢æŸ¥ä»»å‹™æ˜¯å¦å®Œæˆ
                    continue
                except Exception:
                    # éœé»˜å¿½ç•¥å–®ç­†æ¨é€å•é¡Œ
                    continue

            # å¦‚æœæ˜¯æ­£å¸¸å®Œæˆï¼Œæ¨é€æœ€çµ‚å ±å‘Šï¼ˆè‹¥æœ‰ï¼‰
            if not task.cancelled():
                result = task.result()
                ended_at = datetime.now().isoformat(timespec="seconds")
                elapsed = time.perf_counter() - wall_start
                if isinstance(result, dict) and not result.get("error"):
                    # å¯«å…¥æª”æ¡ˆï¼ˆèˆ‡éä¸²æµç«¯é»ä¸€è‡´ï¼‰
                    _write_result_to_file(
                        result, started_at, ended_at, elapsed)
                    final_report = result.get("final_report")
                    if final_report:
                        # æ›´æ–°æš«å­˜æ–‡ä»¶å…§å®¹ä¾› /load-document ä½¿ç”¨
                        _update_document_content(final_report)
                        # æ¨é€æœ€çµ‚å ±å‘Šï¼ŒåŒ…å« task_id ä½œç‚ºæ–‡æª” ID
                        yield sse_event({
                            "type": "final_report",
                            "report": final_report,
                            "document_id": task_id  # ä½¿ç”¨ task_id ä½œç‚ºæ–‡æª” ID
                        })
                else:
                    yield sse_event({"type": "error", "message": "ç ”ç©¶åŸ·è¡Œå¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦"})

        except asyncio.CancelledError:
            # ç”Ÿæˆå™¨è¢«çµ‚æ­¢ï¼ˆé€£ç·šä¸­æ–·ï¼‰ï¼Œç¢ºä¿ä»»å‹™è¢«å–æ¶ˆ
            if not task.done():
                task.cancel()
            raise
        finally:
            # æ¸…ç†ä»»å‹™è¨»å†Š
            if task_id in active_tasks:
                del active_tasks[task_id]
            # æ¸…ç† SSE é€£æ¥è¨»å†Š
            sse_connections.discard(progress_queue)
            # çµ±ä¸€æ”¶å°¾è¨Šè™Ÿï¼ˆè‹¥æ˜¯å®¢æˆ¶ç«¯å–æ¶ˆï¼Œé€™æ®µå¯èƒ½ä¸æœƒè¢«æ”¶åˆ°ï¼‰
            try:
                yield sse_event({"type": "stage_complete", "stage": "deep_researcher"})
            except Exception:
                pass

    headers = {"Cache-Control": "no-cache", "Connection": "keep-alive"}
    return StreamingResponse(event_generator(), media_type="text/event-stream", headers=headers)


# ===== å–æ¶ˆç ”ç©¶ä»»å‹™ API =====
@app.post("/research/cancel")
async def cancel_research(request: dict):
    """å–æ¶ˆç•¶å‰æ­£åœ¨åŸ·è¡Œçš„ç ”ç©¶ä»»å‹™"""
    try:
        task_id_param = request.get("task_id")
        question = request.get("question", "")

        canceled_tasks = []

        # å„ªå…ˆä½¿ç”¨ task_id ç²¾æº–å–æ¶ˆ
        if task_id_param:
            task = active_tasks.get(task_id_param)
            if task and not task.done():
                task.cancel()
                canceled_tasks.append(task_id_param)
                del active_tasks[task_id_param]
        else:
            # å›é€€ï¼šä½¿ç”¨ question å‰ 20 å­—å…ƒä½œç‚ºéµåŒ¹é…æ—¢æœ‰ task_id æ¨¡å¼ research_{ts}_{question[:20]}
            if not question:
                return {"error": "è«‹æä¾› task_id æˆ– question"}
            short = question[:20]
            for tid, task in list(active_tasks.items()):
                if short and tid.endswith(short) and not task.done():
                    task.cancel()
                    canceled_tasks.append(tid)
                    del active_tasks[tid]

        if canceled_tasks:
            logger.info(f"å·²å–æ¶ˆ {len(canceled_tasks)} å€‹ç ”ç©¶ä»»å‹™: {canceled_tasks}")
            return {
                "success": True,
                "message": f"å·²æˆåŠŸå–æ¶ˆ {len(canceled_tasks)} å€‹ç ”ç©¶ä»»å‹™",
                "canceled_tasks": canceled_tasks
            }
        else:
            return {
                "success": False,
                "message": "æœªæ‰¾åˆ°åŒ¹é…çš„ç ”ç©¶ä»»å‹™æˆ–ä»»å‹™å·²å®Œæˆ"
            }

    except Exception as e:
        logger.exception("å–æ¶ˆç ”ç©¶ä»»å‹™å¤±æ•—")
        return {"error": "å–æ¶ˆç ”ç©¶ä»»å‹™å¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦"}


@app.get("/load-document")
async def load_document():
    # ç›´æ¥å›å‚³æš«å­˜æ–‡ä»¶ï¼ˆä¿æŒèˆ‡å‰ç«¯æœŸæœ›çµæ§‹çš„ç›¸å®¹æ€§ï¼‰
    return {
        "title": DOCUMENT_STORE.get("title", "ç ”ç©¶æ–‡ä»¶"),
        "content": DOCUMENT_STORE.get("content", "<p>å°šæœªæœ‰å…§å®¹</p>"),
        "characterLimit": DOCUMENT_STORE.get("characterLimit", 100000)
    }


# ===== æª”æ¡ˆä¸Šå‚³ API =====
@app.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    document_id: str = Query(default="", description="æ–‡æª” IDï¼Œç”¨æ–¼é—œè¯æª”æ¡ˆ")
):
    try:
        logger.info(f"æ”¶åˆ°ä¸Šå‚³è«‹æ±‚: {file.filename}, document_id: {document_id}")
        # æª”åæ·¨åŒ–ï¼šä¿ç•™è‹±æ•¸ã€éƒ¨åˆ†ç¬¦è™Ÿï¼Œé¿å…è·¯å¾‘ç©¿è¶Š
        original_name = file.filename or "unnamed"
        safe_name = original_name
        # "".join(
        #     ch for ch in original_name if ch.isalnum() or ch in (" ", "-", "_", ".")
        # ).strip()
        # logger.info(f"åŸå§‹æª”å: {original_name}, æ·¨åŒ–å¾Œ: {safe_name}")
        # if not safe_name:
        #     raise HTTPException(status_code=400, detail="æª”åç„¡æ•ˆ")

        # æª”æ¡ˆå¤§å°é™åˆ¶ï¼š25MBï¼ˆä»¥ç´¯è¨ˆ bytes æª¢æŸ¥ï¼‰
        total_read = 0

        # æ‰€æœ‰ PDF æª”æ¡ˆéƒ½å…ˆå­˜å…¥ TMP_DIR
        target_path = os.path.join(TMP_DIR, safe_name)

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨ï¼ˆä¾ä½ çš„è¦æ±‚ï¼štmp ç›®éŒ„æœ¬èº«ä¸ç”±ç¨‹å¼å»ºç«‹ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å ±éŒ¯ï¼‰
        if not os.path.isdir(TMP_DIR):
            raise HTTPException(status_code=500, detail="æš«å­˜ç›®éŒ„ä¸å­˜åœ¨ï¼Œè«‹å…ˆå»ºç«‹ tmp ç›®éŒ„")

        with open(target_path, "wb") as out:
            while True:
                chunk = await file.read(1024 * 1024)  # 1MB
                if not chunk:
                    break
                total_read += len(chunk)
                if total_read > MAX_UPLOAD_BYTES:
                    # è¶…å‡ºå¤§å°é™åˆ¶
                    raise HTTPException(status_code=413, detail="æª”æ¡ˆè¶…é 25MB ä¸Šé™")
                out.write(chunk)

        # å»ºç«‹å¯ä¾›å‰ç«¯ç›´æ¥å­˜å–çš„ URL
        file_url = f"/uploads/{safe_name}"

        # æª¢æŸ¥æ˜¯å¦ç‚º PDF æª”æ¡ˆï¼Œè‹¥æ˜¯å‰‡ç«‹å³è™•ç†
        logger.info(
            f"æª”æ¡ˆæª¢æŸ¥: {safe_name}, å‰¯æª”åæª¢æŸ¥: {safe_name.lower().endswith('.pdf')}, document_id: {document_id}")
        if safe_name.lower().endswith('.pdf'):
            try:
                # ç›´æ¥è™•ç† PDFï¼ˆæ‰€æœ‰ PDF éƒ½å…ˆå­˜å…¥ TMP_DIRï¼‰
                logger.info(f"é–‹å§‹è™•ç† PDF: {safe_name}")
                logger.info(f"PDF æª”æ¡ˆè·¯å¾‘: {target_path}")
                logger.info(f"åœ–ç‰‡å­˜æ”¾è·¯å¾‘: {TMP_IMAGE_DIR}")

                new_path = re.sub(r"\.pdf$", ".md", safe_name)
                logger.info(f"é æœŸç”Ÿæˆçš„ MD æª”æ¡ˆ: {new_path}")

                # æ ¹æ“šæ˜¯å¦æœ‰ document_id æ±ºå®šè™•ç†æ–¹å¼
                if document_id:
                    # æœ‰ document_idï¼šç›´æ¥è¼¸å‡ºåˆ° document_file/{document_id} ç›®éŒ„
                    target_dir = os.path.join(DOC_ID_DIR, document_id)
                    os.makedirs(target_dir, exist_ok=True)
                    file_info_path = os.path.join(target_dir, "file_info.json")

                    # ç›´æ¥èª¿ç”¨ file_md.main è¼¸å‡ºåˆ°ç›®æ¨™ç›®éŒ„
                    import file_md
                    file_md.main(target_path, TMP_IMAGE_DIR, target_dir)

                    # æª”æ¡ˆå·²ç¶“åœ¨ç›®æ¨™ç›®éŒ„ï¼Œä¸éœ€è¦ç§»å‹•
                    source_md_path = os.path.join(target_dir, new_path)
                    target_md_path = source_md_path
                else:
                    # æ²’æœ‰ document_idï¼šä½¿ç”¨ TMP_OUTPUT_DIR ç›®éŒ„
                    target_dir = TMP_OUTPUT_DIR
                    file_info_path = os.path.join(target_dir, "file_info.json")

                    # ç›´æ¥èª¿ç”¨ file_md.main è¼¸å‡ºåˆ° TMP_OUTPUT_DIR
                    import file_md
                    file_md.main(target_path, TMP_IMAGE_DIR, TMP_OUTPUT_DIR)

                    # æª”æ¡ˆå·²ç¶“åœ¨ TMP_OUTPUT_DIR ç›®éŒ„ï¼Œä¸éœ€è¦ç§»å‹•
                    source_md_path = os.path.join(TMP_OUTPUT_DIR, new_path)
                    target_md_path = source_md_path

                # æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆæ˜¯å¦å­˜åœ¨
                if os.path.exists(source_md_path):
                    logger.info(f"MD æª”æ¡ˆå·²ç”Ÿæˆ: {source_md_path}")
                else:
                    logger.error(f"æ‰¾ä¸åˆ°ç”Ÿæˆçš„ Markdown æª”æ¡ˆ: {source_md_path}")
                    logger.error(
                        f"ç›®æ¨™ç›®éŒ„å…§å®¹: {os.listdir(target_dir) if os.path.exists(target_dir) else 'ç›®éŒ„ä¸å­˜åœ¨'}")
                    # å³ä½¿æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œä¹Ÿç¹¼çºŒè™•ç†ï¼Œä½†æ¨™è¨˜ç‚ºå¤±æ•—
                    target_md_path = source_md_path  # ä½¿ç”¨åŸå§‹è·¯å¾‘ä½œç‚ºå‚™ç”¨

                # åœ–ç‰‡æª”æ¡ˆä¿ç•™åœ¨ TMP_IMAGE_DIRï¼Œä¸éœ€è¦ç§»å‹•
                if document_id:
                    logger.info(f"æœ‰ document_idï¼Œåœ–ç‰‡æª”æ¡ˆä¿ç•™åœ¨: {TMP_IMAGE_DIR}")
                else:
                    logger.info(f"æ²’æœ‰ document_idï¼Œåœ–ç‰‡æª”æ¡ˆä¿ç•™åœ¨: {TMP_IMAGE_DIR}")

                new_data = {
                    "file_path": target_md_path,
                    "file_name": safe_name.replace('.pdf', ''),
                    "describe": f"é™„ä»¶æª”æ¡ˆï¼š{safe_name}",
                    "document_id": document_id
                }

                # å¦‚æœæª”æ¡ˆå­˜åœ¨ â†’ è®€å–èˆŠè³‡æ–™
                if os.path.exists(file_info_path):
                    with open(file_info_path, "r", encoding="utf-8") as f:
                        try:
                            data = json.load(f)
                        except json.JSONDecodeError:
                            data = []
                else:
                    data = []

                # æ–°å¢è³‡æ–™
                data.append(new_data)

                # å¯«å›æª”æ¡ˆ
                with open(file_info_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)

                print("âœ… æ–°è³‡æ–™å·²å¯«å…¥ï¼")

                logger.info(f"PDF è™•ç†å®Œæˆ: {safe_name}")

                return {
                    "id": safe_name,
                    "url": file_url,
                    "name": safe_name,
                    "processed": True,
                    "status": "completed",
                    "document_id": document_id,
                    "md_file_path": target_md_path
                }
            except Exception as e:
                logger.exception(f"PDF è™•ç†å¤±æ•—: {safe_name}")

                return {
                    "id": safe_name,
                    "url": file_url,
                    "name": safe_name,
                    "processed": False,
                    "status": "failed",
                    "error": str(e),
                    "document_id": document_id
                }
        else:
            # é PDF æª”æ¡ˆ
            return {
                "id": safe_name,
                "url": file_url,
                "name": safe_name,
                "processed": False,
                "status": "skipped",
                "document_id": document_id
            }
    except HTTPException:
        raise
    except Exception:
        logger.exception("æª”æ¡ˆä¸Šå‚³å¤±æ•—")
        raise HTTPException(status_code=500, detail="æª”æ¡ˆä¸Šå‚³å¤±æ•—")


# ===== Markdown æª”æ¡ˆ API =====
@app.get("/markdown")
async def get_markdown(
    document_id: str = Query(default="", description="æ–‡æª” ID"),
    file_name: str = Query(..., description="æª”æ¡ˆåç¨±")
):
    """ç²å– Markdown æª”æ¡ˆå…§å®¹"""
    try:
        logger.info(
            f"æ”¶åˆ° Markdown è«‹æ±‚: document_id={document_id}, file_name={file_name}")

        # å°‡ .pdf æ”¹ç‚º .md
        md_filename = re.sub(r"\.pdf$", ".md", file_name)

        # æ ¹æ“šæ˜¯å¦æœ‰ document_id æ±ºå®šæª”æ¡ˆè·¯å¾‘
        if document_id:
            # æœ‰ document_idï¼šå¾ document_file/{document_id} ç›®éŒ„è®€å–
            file_path = os.path.join(DOC_ID_DIR, document_id, md_filename)
            logger.info(f"æœ‰ document_idï¼Œæª”æ¡ˆè·¯å¾‘: {file_path}")
        else:
            # æ²’æœ‰ document_idï¼šå¾ tmp_doc ç›®éŒ„è®€å–
            file_path = os.path.join(TMP_OUTPUT_DIR, md_filename)
            logger.info(f"æ²’æœ‰ document_idï¼Œæª”æ¡ˆè·¯å¾‘: {file_path}")

        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            logger.warning(f"Markdown æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            raise HTTPException(status_code=404, detail="Markdown æª”æ¡ˆä¸å­˜åœ¨")

        # è®€å–æª”æ¡ˆå…§å®¹
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # è©³ç´°çš„ç·¨ç¢¼æª¢æŸ¥å’Œèª¿è©¦
            logger.info(f"æª”æ¡ˆè®€å–æˆåŠŸ: {file_path}")
            logger.info(f"å…§å®¹é•·åº¦: {len(content)}")
            logger.info(f"å…§å®¹å‰100å­—å…ƒ: {repr(content[:100])}")

            # æª¢æŸ¥å…§å®¹æ˜¯å¦åŒ…å«äº‚ç¢¼
            if content and len(content) > 0:
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                chinese_chars = sum(
                    1 for char in content if '\u4e00' <= char <= '\u9fff')
                logger.info(f"ä¸­æ–‡å­—ç¬¦æ•¸é‡: {chinese_chars}")

                # æª¢æŸ¥æ˜¯å¦æœ‰äº‚ç¢¼å­—ç¬¦
                garbled_chars = sum(1 for char in content if ord(
                    char) > 127 and char not in '\n\r\t')
                logger.info(f"é«˜ASCIIå­—ç¬¦æ•¸é‡: {garbled_chars}")

                # å˜—è©¦æª¢æ¸¬ç·¨ç¢¼å•é¡Œ
                try:
                    # ç¢ºä¿å…§å®¹å¯ä»¥æ­£ç¢ºç·¨ç¢¼ç‚º UTF-8
                    encoded_content = content.encode('utf-8')
                    logger.info(f"UTF-8 ç·¨ç¢¼æˆåŠŸï¼Œç·¨ç¢¼å¾Œé•·åº¦: {len(encoded_content)}")
                except UnicodeEncodeError as e:
                    logger.error(f"UTF-8 ç·¨ç¢¼éŒ¯èª¤: {e}")
                    # å˜—è©¦ä½¿ç”¨å…¶ä»–ç·¨ç¢¼è®€å–
                    with open(file_path, "r", encoding="big5") as f:
                        content = f.read()
                    logger.info(f"ä½¿ç”¨ Big5 ç·¨ç¢¼é‡æ–°è®€å–æˆåŠŸ: {file_path}")
            else:
                logger.warning(f"æª”æ¡ˆå…§å®¹ç‚ºç©º: {file_path}")
                content = f"# {file_name}\n\næª”æ¡ˆå…§å®¹ç‚ºç©ºæˆ–ç„¡æ³•è®€å–ã€‚"

        except UnicodeDecodeError as e:
            logger.error(f"UTF-8 è§£ç¢¼å¤±æ•—: {e}")
            # å˜—è©¦ä½¿ç”¨å…¶ä»–ç·¨ç¢¼
            try:
                with open(file_path, "r", encoding="big5") as f:
                    content = f.read()
                logger.info(f"ä½¿ç”¨ Big5 ç·¨ç¢¼è®€å–æˆåŠŸ: {file_path}")
            except Exception as e2:
                logger.error(f"Big5 ç·¨ç¢¼ä¹Ÿå¤±æ•—: {e2}")
                content = f"# {file_name}\n\næª”æ¡ˆç·¨ç¢¼ç„¡æ³•è­˜åˆ¥ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚"
        except Exception as e:
            logger.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {e}")
            content = f"# {file_name}\n\næª”æ¡ˆè®€å–å¤±æ•—: {str(e)}"

        # å»ºç«‹å›æ‡‰ä¸¦è¨­å®šæ­£ç¢ºçš„ç·¨ç¢¼æ¨™é ­
        from fastapi.responses import JSONResponse
        response = JSONResponse({
            "content": content,
            "fileName": file_name
        })
        response.headers["Content-Type"] = "application/json; charset=utf-8"
        return response

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"è®€å– Markdown æª”æ¡ˆå¤±æ•—: {file_path}")
        raise HTTPException(status_code=500, detail="è®€å– Markdown æª”æ¡ˆå¤±æ•—")


# ===== æ–‡æª”é™„ä»¶ API =====
@app.get("/documents/{document_id}/attachments")
async def get_document_attachments(document_id: str):
    """ç²å–æ–‡æª”çš„é™„ä»¶åˆ—è¡¨"""
    try:
        logger.info(f"æ”¶åˆ°é™„ä»¶åˆ—è¡¨è«‹æ±‚: {document_id}")

        # æª¢æŸ¥æ–‡æª”æ˜¯å¦å­˜åœ¨
        document = collection.find_one({"document_id": document_id})
        if not document:
            logger.warning(f"æ–‡æª”ä¸å­˜åœ¨: {document_id}")
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")

        # è¨ªå•æ–‡æª”ç›®éŒ„
        document_folder = os.path.join(DOC_ID_DIR, document_id)
        attachments = []

        if os.path.exists(document_folder):
            # ç²å–æ‰€æœ‰ .md æª”æ¡ˆ
            for filename in os.listdir(document_folder):
                if filename.endswith('.md'):
                    file_path = os.path.join(document_folder, filename)

                    # ç²å–æª”æ¡ˆè³‡è¨Š
                    file_stat = os.stat(file_path)
                    file_size = file_stat.st_size
                    upload_time = datetime.fromtimestamp(
                        file_stat.st_ctime).isoformat()

                    # ç”Ÿæˆå°æ‡‰çš„ PDF æª”æ¡ˆåç¨±
                    pdf_filename = re.sub(r"\.md$", ".pdf", filename)

                    # ç”Ÿæˆé™„ä»¶ IDï¼ˆä½¿ç”¨æª”æ¡ˆåç¨±çš„ hashï¼‰
                    import hashlib
                    attachment_id = f"att_{hashlib.md5(filename.encode()).hexdigest()[:8]}"

                    attachments.append({
                        "id": attachment_id,
                        "fileName": pdf_filename,
                        "fileSize": file_size,
                        "uploadTime": upload_time,
                        "status": "completed",
                        "convertedUrl": f"http://localhost:8000/uploads/{pdf_filename}"
                    })

        logger.info(f"é™„ä»¶åˆ—è¡¨è¼‰å…¥æˆåŠŸ: {document_id}, å…± {len(attachments)} å€‹é™„ä»¶")

        return {
            "attachments": attachments
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"è¼‰å…¥é™„ä»¶åˆ—è¡¨å¤±æ•—: {document_id}")
        raise HTTPException(status_code=500, detail="è¼‰å…¥é™„ä»¶åˆ—è¡¨å¤±æ•—")


# ===== æ–‡æª”è¼‰å…¥ API =====
@app.get("/documents")
async def get_documents():
    """ç²å–æ‰€æœ‰æ–‡æª”åˆ—è¡¨"""
    try:
        logger.info("æ”¶åˆ°æ–‡æª”åˆ—è¡¨è«‹æ±‚")

        # å¾ MongoDB ç²å–æ‰€æœ‰æ–‡æª”
        documents_cursor = collection.find({}, {
            "document_id": 1,
            "report_title": 1,
            "created_at": 1,
            "updated_at": 1
        }).sort("updated_at", -1)  # æŒ‰æ›´æ–°æ™‚é–“é™åºæ’åˆ—

        documents = []
        for doc in documents_cursor:
            document_id = doc.get("document_id", "")

            # è¨ˆç®—é™„ä»¶æ•¸é‡
            document_folder = os.path.join(
                TMP_DIR, "document_file", document_id)
            attachment_count = 0
            if os.path.exists(document_folder):
                attachment_count = len([f for f in os.listdir(document_folder)
                                        if os.path.isfile(os.path.join(document_folder, f)) and f.endswith('.md')])

            documents.append({
                "id": document_id,
                "title": doc.get("report_title", ""),
                "createdAt": doc.get("created_at", ""),
                "updatedAt": doc.get("updated_at", ""),
                "attachmentCount": attachment_count
            })

        logger.info(f"æ–‡æª”åˆ—è¡¨è¼‰å…¥æˆåŠŸï¼Œå…± {len(documents)} å€‹æ–‡æª”")

        return {
            "documents": documents
        }

    except Exception as e:
        logger.exception("è¼‰å…¥æ–‡æª”åˆ—è¡¨å¤±æ•—")
        raise HTTPException(status_code=500, detail="è¼‰å…¥æ–‡æª”åˆ—è¡¨å¤±æ•—")


@app.get("/documents/{document_id}")
async def get_document(document_id: str):
    """æ ¹æ“šæ–‡æª” ID è¼‰å…¥æ–‡æª”"""
    try:
        logger.info(f"æ”¶åˆ°æ–‡æª”è¼‰å…¥è«‹æ±‚: {document_id}")

        # å¾ MongoDB è¼‰å…¥æ–‡æª”
        document = collection.find_one({"document_id": document_id})

        if not document:
            logger.warning(f"æ–‡æª”ä¸å­˜åœ¨: {document_id}")
            raise HTTPException(status_code=404, detail="æ–‡æª”ä¸å­˜åœ¨")

        # è¨ˆç®—é™„ä»¶æ•¸é‡
        document_folder = os.path.join(TMP_DIR, "document_file", document_id)
        attachment_count = 0
        if os.path.exists(document_folder):
            attachment_count = len([f for f in os.listdir(document_folder)
                                    if os.path.isfile(os.path.join(document_folder, f)) and f.endswith('.md')])

        logger.info(f"æ–‡æª”è¼‰å…¥æˆåŠŸ: {document_id}, é™„ä»¶æ•¸é‡: {attachment_count}")

        return {
            "id": document_id,
            "title": document.get("report_title", ""),
            "content": document.get("content", {}).get("html", ""),
            "createdAt": document.get("created_at", ""),
            "updatedAt": document.get("updated_at", ""),
            "attachmentCount": attachment_count
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"è¼‰å…¥æ–‡æª”å¤±æ•—: {document_id}")
        raise HTTPException(status_code=500, detail="è¼‰å…¥æ–‡æª”å¤±æ•—")


# ===== æ–‡æª”å„²å­˜ API =====
@app.post("/test-save-document")
async def test_save_document(request: dict):
    """æ¸¬è©¦æ–‡æª”å„²å­˜è«‹æ±‚æ ¼å¼"""
    try:
        logger.info(f"æ”¶åˆ°æ¸¬è©¦è«‹æ±‚: {request}")
        return {
            "success": True,
            "message": "è«‹æ±‚æ ¼å¼æ­£ç¢º",
            "received_data": request
        }
    except Exception as e:
        logger.exception("æ¸¬è©¦è«‹æ±‚å¤±æ•—")
        return {"error": str(e)}


@app.post("/test-new-format")
async def test_new_format(request: DocumentSaveRequest):
    """æ¸¬è©¦æ–°çš„çµæ§‹åŒ–è³‡æ–™æ ¼å¼"""
    try:
        logger.info(f"æ”¶åˆ°æ–°æ ¼å¼æ¸¬è©¦è«‹æ±‚: {request.documentId}")
        logger.debug(
            f"è³‡æ–™çµæ§‹: content.htmlé•·åº¦={len(request.data.content.html)}, page_size={request.data.page.size.label}")
        return {
            "success": True,
            "message": "æ–°æ ¼å¼è«‹æ±‚æ­£ç¢º",
            "document_id": request.documentId,
            "content_length": len(request.data.content.html),
            "page_size": request.data.page.size.label
        }
    except Exception as e:
        logger.exception("æ–°æ ¼å¼æ¸¬è©¦å¤±æ•—")
        return {"error": str(e)}


@app.post("/save-document", response_model=DocumentSaveResponse)
async def save_document(request: dict):
    """å„²å­˜æ–‡æª”åˆ° MongoDB"""
    try:
        # å¾è«‹æ±‚ä¸­æå–è³‡æ–™ï¼Œæ”¯æ´å…©ç¨®æ ¼å¼
        document_id = request.get("documentId", "")
        report_title = request.get("reportTitle", "")

        # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°æ ¼å¼ï¼ˆæœ‰ data æ¬„ä½ï¼‰
        if "data" in request:
            data = request["data"]
            content_html = data["content"]["html"]
            content_json = data["content"]["json"]
            content_text = data["content"]["text"]
            page_info = data["page"]
            document_data = data["document"]
        else:
            # èˆŠæ ¼å¼ï¼ˆç›´æ¥åŒ…å« content, page, documentï¼‰
            content_html = request.get("content", {}).get("html", "")
            content_json = request.get("content", {}).get("json", {})
            content_text = request.get("content", {}).get("text", "")
            page_info = request.get("page", {})
            document_data = request.get("document", {})

        logger.info(f"æ”¶åˆ°æ–‡æª”å„²å­˜è«‹æ±‚: {document_id}")
        logger.debug(
            f"è«‹æ±‚è³‡æ–™: documentId={document_id}, reportTitle={report_title}, content_length={len(content_html)}")
        logger.debug(f"å®Œæ•´è«‹æ±‚å…§å®¹: {request}")

        # é©—è­‰å¿…è¦æ¬„ä½
        if not document_id:
            return DocumentSaveResponse(
                success=False,
                message="ç¼ºå°‘å¿…è¦æ¬„ä½: documentId",
                error="documentId is required"
            )

        if not content_html:
            return DocumentSaveResponse(
                success=False,
                message="ç¼ºå°‘å¿…è¦æ¬„ä½: content.html",
                error="content.html is required"
            )

        # æº–å‚™å„²å­˜åˆ° MongoDB çš„æ–‡æª”è³‡æ–™
        mongo_document = {
            "document_id": document_id,
            "report_title": report_title,
            "content": {
                "html": content_html,
                "json": content_json,
                "text": content_text
            },
            "page": page_info,
            "document": document_data,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        # æª¢æŸ¥æ–‡æª”æ˜¯å¦å·²å­˜åœ¨
        existing_doc = collection.find_one({"document_id": document_id})

        if existing_doc:
            # æ›´æ–°ç¾æœ‰æ–‡æª”
            result = collection.update_one(
                {"document_id": document_id},
                {
                    "$set": {
                        "content": {
                            "html": content_html,
                            "json": content_json,
                            "text": content_text
                        },
                        "page": page_info,
                        "document": document_data,
                        "updated_at": datetime.now().isoformat()
                    }
                }
            )
            logger.info(
                f"æ–‡æª”å·²æ›´æ–°: {document_id}, ä¿®æ”¹ç­†æ•¸: {result.modified_count}")
            message = "æ–‡æª”å·²æ›´æ–°"
        else:
            # æ–°æ–‡æª”ï¼šç§»å‹• tmp_doc ä¸­çš„æª”æ¡ˆåˆ°æ–°å»ºè³‡æ–™å¤¾
            try:
                # å»ºç«‹ç›®æ¨™è³‡æ–™å¤¾
                document_folder = os.path.join(
                    TMP_DIR, "document_file", document_id)
                os.makedirs(document_folder, exist_ok=True)

                # ç§»å‹• tmp_doc ä¸­çš„æ‰€æœ‰æª”æ¡ˆåˆ°ç›®æ¨™è³‡æ–™å¤¾
                tmp_doc_folder = os.path.join(TMP_DIR, "tmp_doc")
                if os.path.exists(tmp_doc_folder):
                    for filename in os.listdir(tmp_doc_folder):
                        src_path = os.path.join(tmp_doc_folder, filename)
                        dst_path = os.path.join(document_folder, filename)

                        if os.path.isfile(src_path):
                            # ç§»å‹•æª”æ¡ˆ
                            shutil.move(src_path, dst_path)
                            logger.info(f"æª”æ¡ˆå·²ç§»å‹•: {filename} -> {dst_path}")

                    # ä¿ç•™ tmp_doc è³‡æ–™å¤¾ï¼Œä¸åˆªé™¤
                    logger.info(f"tmp_doc è³‡æ–™å¤¾å·²ä¿ç•™: {tmp_doc_folder}")

                # åœ–ç‰‡è³‡æ–™å¤¾ä¿ç•™åœ¨ TMP_IMAGE_DIRï¼Œä¸éœ€è¦ç§»å‹•
                logger.info(f"åœ–ç‰‡è³‡æ–™å¤¾ä¿ç•™åœ¨: {TMP_IMAGE_DIR}")

                # æ›´æ–°æ–‡æª”è³‡æ–™ï¼ŒåŠ å…¥æª”æ¡ˆè·¯å¾‘è³‡è¨Š
                document_data["file_folder"] = document_folder
                document_data["file_count"] = len([f for f in os.listdir(
                    document_folder) if os.path.isfile(os.path.join(document_folder, f))])

                logger.info(f"æ–°æ–‡æª”æª”æ¡ˆå·²ç§»å‹•åˆ°: {document_folder}")

            except Exception as move_error:
                logger.exception(f"æª”æ¡ˆç§»å‹•å¤±æ•—: {move_error}")
                # å³ä½¿æª”æ¡ˆç§»å‹•å¤±æ•—ï¼Œä»ç¹¼çºŒå„²å­˜æ–‡æª”
                pass

            # æ’å…¥æ–°æ–‡æª”
            result = collection.insert_one(mongo_document)
            logger.info(
                f"æ–°æ–‡æª”å·²å»ºç«‹: {document_id}, æ’å…¥ID: {result.inserted_id}")
            message = "æ–‡æª”å·²å»ºç«‹ä¸¦æª”æ¡ˆå·²ç§»å‹•"

        return DocumentSaveResponse(
            success=True,
            message=message,
            document_id=document_id
        )

    except Exception as e:
        logger.exception(f"æ–‡æª”å„²å­˜å¤±æ•—: {document_id}")

        # æª¢æŸ¥æ˜¯å¦ç‚ºè³‡æ–™é©—è­‰å•é¡Œ
        if "ValidationError" in str(type(e)) or "422" in str(e):
            error_msg = f"è³‡æ–™æ ¼å¼éŒ¯èª¤: {str(e)}"
        # æª¢æŸ¥æ˜¯å¦ç‚º MongoDB é€£ç·šå•é¡Œ
        elif "ServerSelectionTimeoutError" in str(type(e)) or "AutoReconnect" in str(e):
            error_msg = "è³‡æ–™åº«é€£ç·šå•é¡Œï¼Œè«‹ç¨å¾Œé‡è©¦"
        elif "OperationFailure" in str(type(e)):
            error_msg = "è³‡æ–™åº«æ“ä½œå¤±æ•—ï¼Œè«‹æª¢æŸ¥è³‡æ–™æ ¼å¼"
        else:
            error_msg = f"æ–‡æª”å„²å­˜å¤±æ•—: {str(e)}"

        return DocumentSaveResponse(
            success=False,
            message=error_msg,
            error=str(e)
        )


if __name__ == "__main__":
    print("ğŸš€ æ­£åœ¨å•Ÿå‹•ç ”ç©¶æœå‹™å™¨...")
    print("ğŸ“ æœå‹™å™¨åœ°å€: http://127.0.0.1:8000")
    print("ğŸ”¬ ç ”ç©¶ç•Œé¢: http://127.0.0.1:8000/research")
    print("â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœå‹™å™¨")
    print("-" * 50)

    uvicorn.run(app, host="127.0.0.1", port=8000, reload=False)
